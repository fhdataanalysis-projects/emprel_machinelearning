# ğŸ“Š Startup Score Prediction

https://emprel-machinelearning.onrender.com/

O projeto visa propor uma soluÃ§Ã£o para o Desafio 4 - CiÃªncia de Dados para compor uma nova funcionalidade e alimentar o matchmaker de startups com soluÃ§oes na plataforma Coreto da Prefeitura do Recife em parceria com a EMPREL.

Este projeto tem como objetivo prever o score de maturidade de startups com base em diferentes variÃ¡veis relacionadas a traÃ§Ã£o, rede de parceiros, governanÃ§a, tecnologia e aspectos financeiros. 

O pipeline completo envolve:

1. Coleta de dados de um banco PostgreSQL.

2. PrÃ©-processamento e modelagem de Machine Learning.

3. ConstruÃ§Ã£o de uma interface interativa para realizar previsÃµes em novos dados.

## ğŸ— Estrutura do Projeto

``` 
â”œâ”€â”€ .streamlit/                # ConfiguraÃ§Ã£o da interface Streamlit
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ docker/                # Setup do Postgres em container
â”‚   â”‚   â”œâ”€â”€ init/              # Scripts SQL para criar DB e tabelas
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ models_results/        # Resultados de modelos em JSON
â”‚   â”œâ”€â”€ processed/             # Dados processados (train/test/val)
â”‚   â””â”€â”€ raw/                   # Dados originais extraÃ­dos do Postgres
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks usados no fluxo
â”‚   â”œâ”€â”€ eda.ipynb              # AnÃ¡lise exploratÃ³ria de dados
â”‚   â”œâ”€â”€ preprocessing.ipynb    # PrÃ©-processamento
â”‚   â”œâ”€â”€ modeling.ipynb         # Modelagem e avaliaÃ§Ã£o de modelos
â”‚   â”œâ”€â”€ best_model.ipynb       # Rodadas finais do melhor modelo (XGBoost)
â”‚   â”œâ”€â”€ models_results.ipynb   # ComparaÃ§Ã£o de mÃ©tricas entre modelos
â”‚   â””â”€â”€ modelo_startup.pkl     # Pipeline treinado salvo (prÃ©-process + modelo)
â”œâ”€â”€ main.py                    # Script principal para rodar no Streamlit
â”œâ”€â”€ .env                       # VariÃ¡veis de ambiente
â””â”€â”€ README.md                  # DocumentaÃ§Ã£o
```

## ğŸ—„ï¸ Coleta de Dados

Os dados foram gerados artificialmente com base em pesquisas da Ã¡rea de atuaÃ§Ã£o do desafio e nÃ£o envolve o cenÃ¡rio real, tendo como objetivo principal demonstrar a tÃ©cnica e o processo utilizado para avaliar e criar um modelo preditivo capaz de resolver o problema. Os dados gerados artificialmente foram armazenandos em um banco local PostgreSQL via docker.

Scripts SQL para criaÃ§Ã£o do banco e carga inicial estÃ£o em `data/docker/init/` .

A extraÃ§Ã£o foi feita em formato CSV, armazenados em `data/raw/` .

## AnÃ¡lise ExplorÃ¡toria dos Dados
O processo envolveu em identificar possÃ­veis problemas nos dados estabelecer as etapas do prÃ© processamento dos dados de acordo com o tipo de dado de cada feature do dataset.

Com base nisso, identificamos que a maioria das colunas possuiam careter ordinal que foi preciso usar o `OrdinalEncoder` e `OneHotEncoder` para as demais colunas categÃ³ricas. JÃ¡ paraas variÃ¡veis nÃºmericas foi usado o `StandardScaler` para normalizar os dados nÃºmericos em uma escala em comum.

A partir disso, foi realizado alguns testes estÃ¡tisticos iniciais para identificar multicolinearidade entre as variÃ¡veis.

![Matriz de CorrelaÃ§Ã£o](notebooks/images/matriz_corr.png)

A maioria das variÃ¡veis apresenta baixa correlaÃ§Ã£o entre si (prÃ³xima de zero), o que Ã© positivo â†’ significa baixa multicolinearidade.

Algumas correlaÃ§Ãµes chamam atenÃ§Ã£o:

- governanca_financeira vs. score_total (0.64) â†’ correlaÃ§Ã£o moderada-forte, possivelmente variÃ¡vel importante para o modelo.

- mix_receita vs. score_total (0.44) â†’ tambÃ©m tem influÃªncia significativa.

- ticket_medio vs. tipo_servico (0.40) â†’ pode haver relaÃ§Ã£o estrutural entre o tipo de serviÃ§o e o ticket mÃ©dio.

- churn vs. score_total (-0.31) â†’ correlaÃ§Ã£o negativa, empresas com maior score tendem a ter menor churn.

Nenhuma correlaÃ§Ã£o prÃ³xima de 0.9 ou maior â†’ sem risco forte de multicolinearidade que comprometa o modelo.

## ğŸ¤– Modelagem

1. Split em treino (65%), validaÃ§Ã£o(25%) e teste(10%).

2. PrÃ©-processamento

    a. VariÃ¡veis categÃ³ricas â†’ OneHotEncoder / OrdinalEncoder.

    b. VariÃ¡veis numÃ©ricas â†’ StandardScaler.

3. ValidaÃ§Ã£o Cruzada de 5 folds + Grid Search

4. AvaliaÃ§Ã£o de MÃ©tricas

## Modelos testados:

- RegressÃ£o Linear

- KNN

- Random Forest

- MLP (rede neural simples)

- Gradient Boosting

- LightGBM

- XGBoost 



## MÃ©tricas avaliadas:

![forms](notebooks/images/formulas.png)

## Melhor modelo:

XGBoost com hiperparÃ¢metros ajustados via GridSearchCV.

![R 2](notebooks/images/r2models.png)
![MAE](notebooks/images/maemodels.png)
![RMSE](notebooks/images/rmsemodels.png)

ConfiguraÃ§Ã£o escolhida :

```
{
  "colsample_bytree": 1.0,
  "learning_rate": 0.1,
  "max_depth": 3,
  "n_estimators": 300,
  "subsample": 0.8
}
```

## ValidaÃ§Ã£o

O modelo foi rodado 30 vezes na base de teste, a fim de visualizar o comportamento mÃ©dio das mÃ©tricas.

![ImportÃ¢ncia das Features](notebooks/images/30rounds.png)

___
| MÃ©trica | MÃ©dia   | Desvio PadrÃ£o |
|---------|---------|---------------|
| MAE     | 0.5664  | 0.0105        |
| RMSE    | 0.7412  | 0.0117        |
| RÂ²      | 0.9948  | 0.0002        |
___
E tambÃ©m avaliamos a evoluÃ§Ã£o do erro (MAE, RMSE) em relaÃ§Ã£o ao RÂ², que foi a nossa mÃ©trica de decisÃ£o.

![ImportÃ¢ncia das Features](notebooks/images/metric_compar.png)

#### AnÃ¡lise do Modelo Escolhido
ApÃ³s a seleÃ§Ã£o do modelo, uma sÃ©rie de testes estatÃ­sticos foi realizada para avaliar seu desempenho e a validade de suas suposiÃ§Ãµes. A anÃ¡lise dos resÃ­duos, em particular, nos fornece insights valiosos sobre a capacidade do modelo de capturar a relaÃ§Ã£o entre as variÃ¡veis, a distribuiÃ§Ã£o dos erros e a ocorrÃªncia de possÃ­veis vieses.

#### ResÃ­duos vs. PrediÃ§Ãµes

![ImportÃ¢ncia das Features](notebooks/images/residuo-vs-predicao.png)

Os resÃ­duos estÃ£o distribuÃ­dos ao redor de zero, mas hÃ¡ uma leve concentraÃ§Ã£o maior nos valores mÃ©dios.

NÃ£o hÃ¡ padrÃ£o Ã³bvio, o que sugere que o modelo capturou bem a relaÃ§Ã£o entre as variÃ¡veis. Pequenas Ã¡reas de dispersÃ£o maior nos extremos podem indicar que o modelo erra um pouco mais para valores altos ou baixos, mas nada alarmante.

O grÃ¡fico de resÃ­duos vs prediÃ§Ãµes nÃ£o mostra um funil evidente, a variÃ¢ncia dos erros Ã© aproximadamente constante, ou seja, o modelo nÃ£o tende a errar mais em determinados nÃ­veis de prediÃ§Ã£o.

#### GrÃ¡fico Q-Q Plot e Normalidade dos ResÃ­duos


![ImportÃ¢ncia das Features](notebooks/images/qqplot.png)

Shapiro-Wilk: estatÃ­stica = 0.990, p-valor = 0.000

O Q-Q plot dos resÃ­duos seguem a linha central na maior parte, mas os extremos se desviam.

Os resÃ­duos nÃ£o sÃ£o perfeitamente normais, principalmente nas extremidades (valores muito altos ou muito baixos). 

Para XGBoost isso nÃ£o Ã© crÃ­tico, mas indica que o modelo pode subestimar ou superestimar valores extremos.

## ğŸ’» Interface (Streamlit)

ApÃ³s o treinamento, foi criada uma aplicaÃ§Ã£o em Streamlit para:

1. Carregar novos dados de startups.

2. Aplicar o mesmo pipeline de prÃ©-processamento e modelo salvo (modelo_startup.pkl).

3. Exibir o score previsto de maturidade em tempo real.

### Rodando a aplicaÃ§Ã£o Streamlit

```
streamlit run main.py
```

## ğŸš€ Como Executar o Projeto

#### Clonar o repositÃ³rio
```
git clone https://github.com/seu-usuario/startup-maturity-prediction.git
```

Subir o banco Postgres com Docker
```
cd data/docker
docker-compose up -d
```

#### Instalar dependÃªncias
```
pip install -r requirements.txt
```

Rodar a interface Streamlit
```
streamlit run main.py
```

## ğŸ“ˆ Resultados

- O modelo XGBoost apresentou os melhores resultados entre as alternativas.

- A aplicaÃ§Ã£o permite testar cenÃ¡rios e avaliar a maturidade de startups em tempo real.

## ğŸ“Œ PrÃ³ximos Passos

1. Melhorar a interface no Streamlit com grÃ¡ficos interativos.

2. Automatizar o pipeline de atualizaÃ§Ã£o do modelo.

3. Integrar a soluÃ§Ã£o com APIs externas para coleta contÃ­nua de dados.




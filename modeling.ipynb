{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports principais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelos\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Lista global para armazenar os resultados de todas as rodadas\n",
    "resultados_modelos = []\n",
    "\n",
    "def treinar_e_avaliar(modelo, nome_modelo, parametros, x_train, y_train, x_val, y_val):\n",
    "    \"\"\"\n",
    "    Treina e avalia um modelo com GridSearchCV e salva métricas para cada configuração testada.\n",
    "    \"\"\"\n",
    "    gs = GridSearchCV(modelo, parametros, cv=3, scoring='r2', n_jobs=-1, return_train_score=True)\n",
    "    gs.fit(x_train, y_train)\n",
    "    \n",
    "    # Armazena cada configuração rodada (não apenas o melhor)\n",
    "    for i, params in enumerate(gs.cv_results_['params']):\n",
    "        r2_train = gs.cv_results_['mean_train_score'][i]\n",
    "        r2_val = gs.cv_results_['mean_test_score'][i]\n",
    "        \n",
    "        # Após GridSearch, avaliar com predição real na validação (para MAE e RMSE)\n",
    "        modelo_temp = gs.estimator.set_params(**params)\n",
    "        modelo_temp.fit(x_train, y_train)\n",
    "        y_pred_val = modelo_temp.predict(x_val)\n",
    "\n",
    "        mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "        rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "\n",
    "        resultados_modelos.append({\n",
    "            \"Modelo\": nome_modelo,\n",
    "            \"Configuração\": params,\n",
    "            \"R2_Train\": r2_train,\n",
    "            \"R2_Val\": r2_val,\n",
    "            \"MAE_Val\": mae_val,\n",
    "            \"RMSE_Val\": rmse_val\n",
    "        })\n",
    "\n",
    "    return gs.best_estimator_, gs.best_params_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

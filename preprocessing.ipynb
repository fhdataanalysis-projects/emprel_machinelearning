{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/raw/base_maturidade_final.csv', usecols=lambda column: column != 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   clientes_ativos         10000 non-null  int64  \n",
      " 1   faturamento_mensal      10000 non-null  int64  \n",
      " 2   faturamento_acumulado   10000 non-null  int64  \n",
      " 3   anos_empresa            10000 non-null  float64\n",
      " 4   tipo_servico            10000 non-null  object \n",
      " 5   ticket_medio            10000 non-null  float64\n",
      " 6   mix_receita             10000 non-null  object \n",
      " 7   canais_vendas           10000 non-null  int64  \n",
      " 8   churn                   10000 non-null  float64\n",
      " 9   parcerias               10000 non-null  object \n",
      " 10  investimento_externo    10000 non-null  object \n",
      " 11  branding_reputacao      10000 non-null  object \n",
      " 12  network_time            10000 non-null  object \n",
      " 13  uso_tecnologia          10000 non-null  object \n",
      " 14  roadmap_produto         10000 non-null  object \n",
      " 15  nps                     10000 non-null  int64  \n",
      " 16  eficiencia_operacional  10000 non-null  object \n",
      " 17  escala_tecnologica      10000 non-null  object \n",
      " 18  financas_unidade        10000 non-null  object \n",
      " 19  headcount               10000 non-null  int64  \n",
      " 20  experiencia_lideranca   10000 non-null  object \n",
      " 21  treinamento             10000 non-null  object \n",
      " 22  rotatividade_time       10000 non-null  float64\n",
      " 23  governanca_financeira   10000 non-null  object \n",
      " 24  score_total             10000 non-null  float64\n",
      "dtypes: float64(5), int64(6), object(14)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunas categoricas\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# colunas numericas\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna: tipo_servico\n",
      "['Serviço' 'Produto']\n",
      "\n",
      "Coluna: mix_receita\n",
      "['3–5 clientes >50%' 'Receita diversificada' '1–2 clientes >50%']\n",
      "\n",
      "Coluna: parcerias\n",
      "['Algumas' 'Poucas' 'Muitas' 'Nenhuma']\n",
      "\n",
      "Coluna: investimento_externo\n",
      "['Série A+' 'Aceleradora/Anjo' 'Não' 'Seed/Pré-Série A']\n",
      "\n",
      "Coluna: branding_reputacao\n",
      "['Reconhecimento forte' 'Não reconhecida' 'Algum reconhecimento']\n",
      "\n",
      "Coluna: network_time\n",
      "['Sim, forte' 'Ocasionalmente' 'Não']\n",
      "\n",
      "Coluna: uso_tecnologia\n",
      "['Alto' 'Médio' 'Baixo']\n",
      "\n",
      "Coluna: roadmap_produto\n",
      "['Parcial' 'Não existe' 'Claro e executado']\n",
      "\n",
      "Coluna: eficiencia_operacional\n",
      "['Parcialmente' 'Quase tudo' 'Quase nada']\n",
      "\n",
      "Coluna: escala_tecnologica\n",
      "['Parcialmente' 'Não' 'Sim']\n",
      "\n",
      "Coluna: financas_unidade\n",
      "['Algumas' 'Não' 'Sim, regularmente']\n",
      "\n",
      "Coluna: experiencia_lideranca\n",
      "['Experiência forte' 'Sem experiência' 'Experiência parcial']\n",
      "\n",
      "Coluna: treinamento\n",
      "['Às vezes' 'Regularmente' 'Nunca']\n",
      "\n",
      "Coluna: governanca_financeira\n",
      "['Não existem controles' 'DRE e auditoria' 'Controles básicos']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f'Coluna: {col}')\n",
    "    print(df[col].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (6500, 24), y_train shape: (6500,)\n",
      "x_test shape: (2500, 24), y_test shape: (2500,)\n",
      "x_validation shape: (1000, 24), y_validation shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# divisão treino, teste e validaçao em csv diferentes 65/25/10 \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, temp_df = train_test_split(df, test_size=0.35, random_state=42)\n",
    "test_df, val_df = train_test_split(temp_df, test_size=0.2857, random_state=42) # 0.2857 * 0.35 = 0.10\n",
    "# salvando os datasets\n",
    "\n",
    "# Separando features (X) e labels (y)\n",
    "target_column = 'score_total'\n",
    "\n",
    "x_train = train_df.drop(columns=[target_column])\n",
    "y_train = train_df[target_column]\n",
    "\n",
    "x_test = test_df.drop(columns=[target_column])\n",
    "y_test = test_df[target_column]\n",
    "\n",
    "x_validation = val_df.drop(columns=[target_column])\n",
    "y_validation = val_df[target_column]\n",
    "\n",
    "# Salvando os datasets em arquivos CSV\n",
    "x_train.to_csv('data/raw/test_split/x_train.csv', index=False)\n",
    "y_train.to_csv('data/raw/test_split/y_train.csv', index=False)\n",
    "x_test.to_csv('data/raw/test_split/x_test.csv', index=False)\n",
    "y_test.to_csv('data/raw/test_split/y_test.csv', index=False)\n",
    "x_validation.to_csv('data/raw/test_split/x_validation.csv', index=False)\n",
    "y_validation.to_csv('data/raw/test_split/y_validation.csv', index=False)\n",
    "\n",
    "# Exibindo as formas dos datasets\n",
    "print(f'x_train shape: {x_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'x_test shape: {x_test.shape}, y_test shape: {y_test.shape}')\n",
    "print(f'x_validation shape: {x_validation.shape}, y_validation shape: {y_validation.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- 1. Carregando os CSVs ---\n",
    "x_train = pd.read_csv('data/raw/test_split/x_train.csv')\n",
    "y_train = pd.read_csv('data/raw/test_split/y_train.csv')\n",
    "\n",
    "x_test = pd.read_csv('data/raw/test_split/x_test.csv')\n",
    "y_test = pd.read_csv('data/raw/test_split/y_test.csv')\n",
    "\n",
    "x_validation = pd.read_csv('data/raw/test_split/x_validation.csv')\n",
    "y_validation = pd.read_csv('data/raw/test_split/y_validation.csv')\n",
    "\n",
    "# --- 2. Definindo colunas categóricas ---\n",
    "col_one_hot = ['tipo_servico']\n",
    "col_ordinal = [\n",
    "    'mix_receita', 'parcerias', 'investimento_externo', 'branding_reputacao',\n",
    "    'network_time', 'uso_tecnologia', 'roadmap_produto', 'eficiencia_operacional',\n",
    "    'escala_tecnologica', 'financas_unidade', 'experiencia_lideranca',\n",
    "    'treinamento', 'governanca_financeira'\n",
    "]\n",
    "\n",
    "# --- 3. Ordem das categorias para o OrdinalEncoder ---\n",
    "ordinal_categories = [\n",
    "    ['1–2 clientes >50%', '3–5 clientes >50%', 'Receita diversificada'],      \n",
    "    ['Nenhuma', 'Poucas', 'Algumas', 'Muitas'],                               \n",
    "    ['Não', 'Aceleradora/Anjo', 'Seed/Pré-Série A', 'Série A+'],              \n",
    "    ['Não reconhecida', 'Algum reconhecimento', 'Reconhecimento forte'],      \n",
    "    ['Não', 'Ocasionalmente', 'Sim, forte'],                                  \n",
    "    ['Baixo', 'Médio', 'Alto'],                                               \n",
    "    ['Não existe', 'Parcial', 'Claro e executado'],                           \n",
    "    ['Quase nada', 'Parcialmente', 'Quase tudo'],                             \n",
    "    ['Não', 'Parcialmente', 'Sim'],                                           \n",
    "    ['Não', 'Algumas', 'Sim, regularmente'],                                  \n",
    "    ['Sem experiência', 'Experiência parcial', 'Experiência forte'],          \n",
    "    ['Nunca', 'Às vezes', 'Regularmente'],                                    \n",
    "    ['Não existem controles', 'Controles básicos', 'DRE e auditoria']         \n",
    "]\n",
    "\n",
    "# --- 4. Criando encoders ---\n",
    "one_hot_encoder = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "ordinal_encoder = OrdinalEncoder(categories=ordinal_categories)\n",
    "\n",
    "# --- 5. Criando pré-processador com normalização ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', one_hot_encoder, col_one_hot),\n",
    "        ('ordinal', ordinal_encoder, col_ordinal),\n",
    "        ('scaler', StandardScaler(), list(set(x_train.columns) - set(col_one_hot) - set(col_ordinal)))\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# --- 6. Criar pipeline final ---\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# --- 7. Fit no treino e transform nos outros ---\n",
    "X_train_transformed = pipeline.fit_transform(x_train)\n",
    "X_test_transformed = pipeline.transform(x_test)\n",
    "X_val_transformed = pipeline.transform(x_validation)\n",
    "\n",
    "# --- 8. Converter para DataFrame e salvar em CSV ---\n",
    "# Pegar nomes das colunas geradas pelo OneHotEncoder e OrdinalEncoder\n",
    "one_hot_cols = pipeline.named_steps['preprocessor'].named_transformers_['onehot'].get_feature_names_out(col_one_hot)\n",
    "ordinal_cols = col_ordinal\n",
    "numeric_cols = list(set(x_train.columns) - set(col_one_hot) - set(col_ordinal))\n",
    "\n",
    "processed_columns = list(one_hot_cols) + ordinal_cols + numeric_cols\n",
    "\n",
    "# Criar DataFrames\n",
    "X_train_df = pd.DataFrame(X_train_transformed, columns=processed_columns, index=x_train.index)\n",
    "X_test_df = pd.DataFrame(X_test_transformed, columns=processed_columns, index=x_test.index)\n",
    "X_val_df = pd.DataFrame(X_val_transformed, columns=processed_columns, index=x_validation.index)\n",
    "\n",
    "# Salvar CSVs\n",
    "X_train_df.to_csv('data/processed/x_train_encoded.csv', index=False)\n",
    "X_test_df.to_csv('data/processed/x_test_encoded.csv', index=False)\n",
    "X_val_df.to_csv('data/processed/x_validation_encoded.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
